# -*- coding: utf-8 -*-
"""Titanic Dataset Sourcecode.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iYXFclw3ay5CgAWCMPtiBVa9mll_PZYF

## Imports
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import sklearn.preprocessing as skpre 
import numpy as np

from sklearn import linear_model
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split
from scipy.special import expit
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score
from sklearn import tree
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import RandomizedSearchCV

"""## Reading csv"""

df_titanic = pd.read_csv("/content/drive/My Drive/Data Science/Titanic Dataset Exploration/titanic.csv")

"""## Removing Null Values

Finding which features have null values
"""

df_titanic.isnull().sum()

"""Finding stats of dataset before manipulation"""

df_titanic.mean()

df_titanic.describe()

df_titanic.mode()

"""Dropping cabin as it does not relate to the data I am trying to display / model"""

df_titanic = df_titanic.drop(columns = ['Cabin'])

df_titanic

"""Checking null values after cabin feature is dropped"""

df_titanic.isnull().sum()

"""Dropping rows that have null values. This time I am not dropping the age feature as **it does** relate to what I am trying to display / model"""

df_titanic = df_titanic.dropna(axis = 0, how = 'any')

df_titanic

"""Finally, there are no null values"""

df_titanic.isnull().sum()

"""## Adding features"""

df_titanic['is_male'] = df_titanic['Sex'] == 'male'
df_titanic['is_female'] = df_titanic['Sex'] == 'female'
df_titanic

"""Creating a new feature (Sex-Class). Male and travelling in first class = male1"""

df_titanic['Sex-Class'] = df_titanic['Sex'] + df_titanic['Pclass'].astype(str) 
df_titanic

df_titanic.mean()

"""## Finding Statistical Values

Finding out the percent of males and females who survived
"""

females_survived = ((df_titanic['is_female']) & (df_titanic['Survived'])).sum()
females_total = (df_titanic['is_female']).sum()
females_survive_percent = (females_survived / females_total) * 100
females_survive_percent

males_survived = ((df_titanic['is_male']) & (df_titanic['Survived'])).sum()
males_total = (df_titanic['is_male']).sum()
males_survive_percent = (males_survived / males_total) * 100
males_survive_percent

"""Finding out the percent of how many people in each Sex-Class survived"""

female1_survive = ((df_titanic['Sex-Class'] == 'female1') & (df_titanic['Survived'])).sum()
female1_total = (df_titanic['Sex-Class'] == 'female1').sum()
female1_survive_percent = (female1_survive / female1_total) * 100
female1_survive_percent # 96% of females in first class survived

female2_survive = ((df_titanic['Sex-Class'] == 'female2') & (df_titanic['Survived'])).sum()
female2_total = (df_titanic['Sex-Class'] == 'female2').sum()
female2_survive_percent = (female2_survive / female2_total) * 100
female2_survive_percent

female3_survive = ((df_titanic['Sex-Class'] == 'female3') & (df_titanic['Survived'])).sum()
female3_total = (df_titanic['Sex-Class'] == 'female3').sum()
female3_survive_percent = (female3_survive / female3_total) * 100
female3_survive_percent

male1_survive = ((df_titanic['Sex-Class'] == 'male1') & (df_titanic['Survived'])).sum()
male1_total = (df_titanic['Sex-Class'] == 'male1').sum()
male1_survive_percent = (male1_survive / male1_total) * 100
male1_survive_percent

male2_survive = ((df_titanic['Sex-Class'] == 'male2') & (df_titanic['Survived'])).sum()
male2_total = (df_titanic['Sex-Class'] == 'male2').sum()
male2_survive_percent = (male2_survive / male2_total) * 100
male2_survive_percent

male3_survive = ((df_titanic['Sex-Class'] == 'male3') & (df_titanic['Survived'])).sum()
male3_total = (df_titanic['Sex-Class'] == 'male3').sum()
male3_survive_percent = (male3_survive / male3_total) * 100
male3_survive_percent

"""## Visualization"""

sns.catplot(data = df_titanic, x = 'Pclass', y = 'Age', hue = 'Survived')
fig = plt.gcf()
fig.suptitle('Titanic Dataset Plot (Class, Age, Survived)', y = 1.02)
fig.show()

sns.catplot(data = df_titanic, x = 'Sex', y = 'Age', hue = 'Survived')
fig = plt.gcf()
fig.suptitle('Titanic Dataset Plot (Sex, Age, Survived)', y = 1.02)
fig.show()

sns.catplot(data = df_titanic, x = 'Sex-Class', y = 'Age', hue = 'Survived')
fig = plt.gcf()
fig.suptitle('Titanic Dataset Plot (Sex-Class, Age, Survived)', y = 1.02)
fig.show()

"""## Fixing Data for ML Models

Dropping columns which will are not going to be used in visualization or model. **df_titanic2** will be used for building models.
"""

df_titanic2 = df_titanic.copy()
df_titanic2 = df_titanic.drop(columns  = ['Name', 'Ticket', 'Sex-Class', 'is_male', 'is_female'])
df_titanic2

df_titanic2['Sex'] = df_titanic2['Sex'].map({'male':1,'female':0})

df_titanic2['Embarked'] = df_titanic2['Embarked'].map({'S':0,'C':1, 'Q':2})

df_titanic2

"""Removing Survived Column"""

true_survival = df_titanic2['Survived']
df_titanic2 = df_titanic2.drop(columns = ['Survived'])

df_titanic2

"""## Finding X_train, X_test, y_train, y_test"""

X_train, X_test, y_train, y_test = train_test_split(df_titanic2, true_survival, test_size = 0.20)

"""## Random Forest Classifier"""

rf_classifier = RandomForestClassifier(n_estimators = 50, max_depth=3, random_state=5)
rf_precision_scores = cross_val_score(rf_classifier, df_titanic2, true_survival, scoring = 'precision', cv=5)
rf_precision_scores.mean()

"""## Random Forest Classifier with Hyperparameter Optimization"""

rf_classifier2 = RandomForestClassifier()
param_space = { 'n_estimators' : [3,10,30,50,100], 
               'max_depth' : [5,10,50,100], 
               'min_samples_split' : [2,10,50], 
               'min_samples_leaf' : [1, 10, 100], 
               'max_features' : [2,4,6,8] }

rf_classifier2_cv = RandomizedSearchCV(rf_classifier2, param_space, n_iter=10, scoring = 'neg_root_mean_squared_error', cv = 5 )
search = rf_classifier2_cv.fit(X_train, y_train)

search.best_params_

rf_classifier2 = RandomForestClassifier(max_depth=100, max_features=2, min_samples_leaf=1, min_samples_split=10, n_estimators=30)
rf_classifier2.fit(X_train, y_train)

rf2_predictions = rf_classifier2.predict(X_test)

mean_squared_error(y_test, rf2_predictions)

rf2_precision_scores = cross_val_score(rf_classifier2, df_titanic2, true_survival, scoring = 'precision', cv=5)
rf2_precision_scores.mean()

rf2_recall_scores = cross_val_score(rf_classifier2, df_titanic2, true_survival, scoring = 'recall', cv=5)
rf2_recall_scores.mean()

accuracy_score(y_test, rf2_predictions)

f1score_rf2  = 2 * (( rf2_precision_scores.mean() * rf2_recall_scores.mean()) / (rf2_precision_scores.mean() + rf2_recall_scores.mean()))
f1score_rf2

"""## Logistic Regression"""

logistic_regression_model = linear_model.LogisticRegression(max_iter=800)

logistic_regression_model.fit(X = X_train, y = y_train)

predictions = logistic_regression_model.predict(X = X_test)

mean_absolute_error(y_test, predictions)

logistic_regression_model.coef_

lr_precision_scores = cross_val_score(logistic_regression_model, df_titanic2, true_survival, scoring = 'precision', cv=5)
lr_precision_scores.mean()

lr_recall_scores = cross_val_score(logistic_regression_model, df_titanic2, true_survival, scoring = 'recall', cv=5)
lr_recall_scores.mean()

accuracy_score(y_test, predictions)

f1score_lr  = 2 * (( lr_precision_scores.mean() * lr_recall_scores.mean()) / (lr_precision_scores.mean() + lr_recall_scores.mean()))
f1score_lr

cf_matrix = confusion_matrix(y_test, predictions)

sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, fmt='.2%', cmap='Greens')

"""## Decision Tree Classifier"""

tree_model = tree.DecisionTreeClassifier()

tree_model.fit(X_train, y_train)
predictions_tree = tree_model.predict(X_test)
predictions_tree

mean_absolute_error(y_test, predictions_tree)

tm_precision_scores = cross_val_score(tree_model, df_titanic2, true_survival, scoring = 'precision', cv=5)
tm_precision_scores.mean()

tm_recall_scores = cross_val_score(tree_model, df_titanic2, true_survival, scoring = 'recall', cv=5)
tm_recall_scores.mean()

accuracy_score(y_test, predictions_tree)

f1score_tm  = 2 * (( tm_precision_scores.mean() * tm_recall_scores.mean()) / (tm_precision_scores.mean() + tm_recall_scores.mean()))
f1score_tm

cf_matrix2 = confusion_matrix(y_test, predictions_tree)

sns.heatmap(cf_matrix2/np.sum(cf_matrix2), annot=True, fmt='.2%', cmap='Reds')

"""# Plotting all the features"""

sns.pairplot(data = df_titanic, hue = 'Survived')
plt.show()